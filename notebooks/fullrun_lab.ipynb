{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-howto",
   "metadata": {},
   "source": [
    "# Fullrun-Notebook (Etappe 01–03)\n",
    "\n",
    "Dieses Notebook ist eine optionale „Bedienoberfläche“ für `fullrun.py`: Parameter auswählen, Lauf starten, danach Ergebnisse anschauen und bei Bedarf Exporte für die Arbeit kopieren. Alles geht auch ohne Notebook direkt über die CLI.\n",
    "\n",
    "Kurz zur Einordnung:\n",
    "- Das Notebook startet `python3 fullrun.py ...` als Subprozess (Interpreter = `sys.executable`).\n",
    "- Für die Nachvollziehbarkeit sind die erzeugten Ausgabeordner entscheidend (z.B. `fullrun_out/...`) inkl. `metadata.json`/`runs.jsonl` und den Exporten unter `stage3_evaluation/`.\n",
    "- Begriffe und Zielgrößen sind wie im schriftlichen Teil; hier geht es wirklich nur um Ausführung und Export.\n",
    "\n",
    "## Grober Ablauf\n",
    "1. Umgebung prüfen\n",
    "2. Parameter wählen und als `plan.json` speichern\n",
    "3. Lauf starten (Live-Ausgabe + `notebook_run.log`)\n",
    "4. Auswertung aus `stage3_evaluation/` ansehen\n",
    "5. Gewünschte Tabellen/Abbildungen/CSVs nach `thesis_assets/<run_name>/` kopieren\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-md",
   "metadata": {},
   "source": [
    "## 2) Umgebung prüfen\n",
    "\n",
    "Gedacht ist das Notebook für die Conda-Umgebung aus `environment.yml`. Standardmäßig wird `sys.executable` als Interpreter verwendet (also der Python, mit dem das Notebook läuft).\n",
    "\n",
    "Das Projektwurzelverzeichnis wird automatisch gesucht (Start bei `Path.cwd()`, dann nach oben, bis `fullrun.py` gefunden wird).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "env-code",
   "metadata": {},
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, IFrame, clear_output\n",
    "\n",
    "\n",
    "EXPECTED_CONDA_ENV = \"ba_pipeline\"\n",
    "\n",
    "\n",
    "def _html_box(text: str, *, kind: str = \"info\") -> HTML:\n",
    "    colors = {\n",
    "        \"info\": (\"#0b5394\", \"#d9e8ff\"),\n",
    "        \"warn\": (\"#7f6000\", \"#fff2cc\"),\n",
    "        \"error\": (\"#990000\", \"#f4cccc\"),\n",
    "        \"ok\": (\"#274e13\", \"#d9ead3\"),\n",
    "    }\n",
    "    border, bg = colors.get(kind, colors[\"info\"])\n",
    "    safe = (\n",
    "        str(text)\n",
    "        .replace(\"&\", \"&amp;\")\n",
    "        .replace(\"<\", \"&lt;\")\n",
    "        .replace(\">\", \"&gt;\")\n",
    "        .replace(\"\\n\", \"<br>\")\n",
    "    )\n",
    "    return HTML(\n",
    "        \"\"\"\n",
    "        <div style=\"border:1px solid {border}; background:{bg}; padding:10px; border-radius:6px;\">\n",
    "          <div style=\"font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial; font-size: 13px; line-height:1.35;\">{safe}</div>\n",
    "        </div>\n",
    "        \"\"\".format(border=border, bg=bg, safe=safe)\n",
    "    )\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    start_path = (start or Path.cwd()).resolve()\n",
    "    for p in [start_path, *start_path.parents]:\n",
    "        if (p / \"fullrun.py\").is_file():\n",
    "            return p\n",
    "    raise FileNotFoundError(\n",
    "        \"Projekt-Root konnte nicht gefunden werden (fullrun.py nicht entdeckt).\\n\"\n",
    "        f\"Start: {start_path}\\n\"\n",
    "        \"Tipp: Starte Jupyter im Projekt-Root oder in einem Unterordner davon.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Basis-Infos\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"sys.version:\", sys.version.replace(\"\\n\", \" \"))\n",
    "print(\"CONDA_DEFAULT_ENV:\", os.environ.get(\"CONDA_DEFAULT_ENV\"))\n",
    "print(\"os.name:\", os.name)\n",
    "print(\"sys.platform:\", sys.platform)\n",
    "print(\"CWD:\", Path.cwd())\n",
    "\n",
    "\n",
    "# Conda-Env Warnung\n",
    "if os.environ.get(\"CONDA_DEFAULT_ENV\") != EXPECTED_CONDA_ENV:\n",
    "    display(\n",
    "        _html_box(\n",
    "            \"WARNUNG: CONDA_DEFAULT_ENV ist nicht 'ba_pipeline'.\\n\"\n",
    "            \"Empfohlen: Terminal öffnen und ausführen:\\n\"\n",
    "            \"  conda activate ba_pipeline\\n\"\n",
    "            \"Dann Jupyter aus genau diesem Terminal starten.\",\n",
    "            kind=\"warn\",\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    display(_html_box(\"OK: ba_pipeline ist aktiv.\", kind=\"ok\"))\n",
    "\n",
    "\n",
    "# Projekt-Root Detection (abbrechen, falls nicht gefunden)\n",
    "try:\n",
    "    repo_root = find_repo_root()\n",
    "except Exception as e:\n",
    "    raise SystemExit(str(e)) from e\n",
    "\n",
    "print(\"Projekt-Root:\", repo_root)\n",
    "\n",
    "\n",
    "# Kleine Utilities (für spätere Zellen)\n",
    "def _utc_now_iso() -> str:\n",
    "    return datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "\n",
    "\n",
    "def _read_json(path: Path) -> dict | None:\n",
    "    try:\n",
    "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _get_selected_run_root() -> Path | None:\n",
    "    val = globals().get(\"SELECTED_RUN_ROOT\")\n",
    "    if not val:\n",
    "        return None\n",
    "    p = Path(str(val))\n",
    "    return p if p.exists() else None\n",
    "\n",
    "\n",
    "# Import-Check (Button)\n",
    "btn_import_check = widgets.Button(description=\"Imports prüfen\", button_style=\"info\")\n",
    "out_import_check = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "\n",
    "\n",
    "def _try_import(name: str):\n",
    "    try:\n",
    "        mod = __import__(name)\n",
    "        ver = getattr(mod, \"__version__\", \"?\")\n",
    "        return True, ver, None\n",
    "    except Exception as e:\n",
    "        return False, None, f\"{type(e).__name__}: {e}\"\n",
    "\n",
    "\n",
    "def _on_import_check(_):\n",
    "    with out_import_check:\n",
    "        clear_output()\n",
    "        print(\"Import-Check (offline):\")\n",
    "        for name in [\"numpy\", \"pandas\", \"matplotlib\", \"ipywidgets\"]:\n",
    "            ok, ver, err = _try_import(name)\n",
    "            if ok:\n",
    "                print(f\"  [OK]   {name} (version: {ver})\")\n",
    "            else:\n",
    "                print(f\"  [FAIL] {name} -> {err}\")\n",
    "        ok, ver, err = _try_import(\"fitz\")\n",
    "        if ok:\n",
    "            print(f\"  [OK]   fitz (PyMuPDF) (version: {ver})\")\n",
    "        else:\n",
    "            print(\"  [INFO] fitz (PyMuPDF) nicht verfügbar -> PDF-Preview via IFrame/Link.\")\n",
    "\n",
    "\n",
    "btn_import_check.on_click(_on_import_check)\n",
    "display(widgets.VBox([btn_import_check, out_import_check]))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "plan-md",
   "metadata": {},
   "source": [
    "## 3) PLANUNG (Widgets)\n",
    "\n",
    "Hier stelle ich die Parameter für einen Lauf zusammen, ohne fachliche Logik zu duplizieren: Aus den Eingaben baut das Notebook den `python3 fullrun.py ...`-Befehl. `Validieren` prüft kurz, ob `fullrun.py --help` mit dem aktuellen Interpreter läuft. `Plan schreiben` legt den Ausgabeordner an und speichert eine Momentaufnahme als `plan.json` (inkl. Commit + `git_dirty`, falls Git verfügbar ist).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "plan-code",
   "metadata": {},
   "source": [
    "# PLAN UI\n",
    "\n",
    "def _sanitize_label(raw: str) -> str:\n",
    "    t = str(raw or \"\").strip()\n",
    "    if not t:\n",
    "        return \"run\"\n",
    "    t = re.sub(r\"[\\s/\\\\:]+\", \"_\", t)\n",
    "    t = re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", t)\n",
    "    t = t.strip(\"._-\")\n",
    "    return t or \"run\"\n",
    "\n",
    "\n",
    "def _utc_now_iso() -> str:\n",
    "    return datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "\n",
    "\n",
    "def _git_snapshot(cwd: Path):\n",
    "    commit_hash = None\n",
    "    git_dirty = None\n",
    "    note = None\n",
    "\n",
    "    try:\n",
    "        r1 = subprocess.run(\n",
    "            [\"git\", \"rev-parse\", \"HEAD\"],\n",
    "            cwd=str(cwd),\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            encoding=\"utf-8\",\n",
    "            errors=\"replace\",\n",
    "            timeout=5,\n",
    "        )\n",
    "        if r1.returncode == 0:\n",
    "            commit_hash = (r1.stdout or \"\").strip() or None\n",
    "        else:\n",
    "            note = (r1.stderr or r1.stdout or \"\").strip() or \"git rev-parse fehlgeschlagen\"\n",
    "\n",
    "        r2 = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\"],\n",
    "            cwd=str(cwd),\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            encoding=\"utf-8\",\n",
    "            errors=\"replace\",\n",
    "            timeout=5,\n",
    "        )\n",
    "        if r2.returncode == 0:\n",
    "            git_dirty = bool((r2.stdout or \"\").strip())\n",
    "        else:\n",
    "            if note is None:\n",
    "                note = (r2.stderr or r2.stdout or \"\").strip() or \"git status fehlgeschlagen\"\n",
    "    except FileNotFoundError:\n",
    "        note = \"git unavailable\"\n",
    "    except Exception as e:\n",
    "        note = f\"git error: {type(e).__name__}: {e}\"\n",
    "\n",
    "    return commit_hash, git_dirty, note\n",
    "\n",
    "\n",
    "w_base_out = widgets.Text(value=\"runs\", description=\"Out-Basis\", layout=widgets.Layout(width=\"420px\"))\n",
    "w_timestamped = widgets.Checkbox(value=True, description=\"Timestamped Out-Ordner\")\n",
    "w_label = widgets.Text(value=\"playground\", description=\"Label\", layout=widgets.Layout(width=\"420px\"))\n",
    "w_resume = widgets.Checkbox(value=True, description=\"Resume\")\n",
    "w_dry_run = widgets.Checkbox(value=False, description=\"Dry-run\")\n",
    "w_methods = widgets.SelectMultiple(\n",
    "    options=[\"V1\", \"V2\", \"V3\", \"V4\"],\n",
    "    value=(\"V1\", \"V2\", \"V3\", \"V4\"),\n",
    "    description=\"Verfahren\",\n",
    "    layout=widgets.Layout(width=\"220px\", height=\"110px\"),\n",
    ")\n",
    "w_conda_run = widgets.Checkbox(value=False, description=\"Conda run\")\n",
    "w_conda_env = widgets.Text(value=\"ba_pipeline\", description=\"Env\", layout=widgets.Layout(width=\"320px\"))\n",
    "\n",
    "btn_validate = widgets.Button(description=\"Validieren\", button_style=\"warning\")\n",
    "btn_write_plan = widgets.Button(description=\"Plan schreiben\", button_style=\"success\")\n",
    "out_plan = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "\n",
    "\n",
    "def _build_out_dir_rel(now: datetime.datetime | None = None) -> Path:\n",
    "    base = Path((w_base_out.value or \"runs\").strip() or \"runs\")\n",
    "    lbl = _sanitize_label(w_label.value)\n",
    "    if w_timestamped.value:\n",
    "        now = now or datetime.datetime.now()\n",
    "        stamp = now.strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "        return base / f\"{stamp}_{lbl}\"\n",
    "    return base / lbl\n",
    "\n",
    "\n",
    "def _build_python_launcher() -> list[str]:\n",
    "    if w_conda_run.value:\n",
    "        env_name = (w_conda_env.value or EXPECTED_CONDA_ENV).strip() or EXPECTED_CONDA_ENV\n",
    "        return [\"conda\", \"run\", \"-n\", env_name, \"python\"]\n",
    "    return [sys.executable]\n",
    "\n",
    "\n",
    "def build_plan_spec(now: datetime.datetime | None = None) -> dict:\n",
    "    methods = [str(m).strip() for m in w_methods.value]\n",
    "    if not methods:\n",
    "        raise ValueError(\"methods ist leer (mind. ein Verfahren auswählen).\")\n",
    "\n",
    "    out_dir_rel = _build_out_dir_rel(now=now)\n",
    "    out_dir_abs = (repo_root / out_dir_rel).resolve()\n",
    "\n",
    "    launcher = _build_python_launcher()\n",
    "    cmd = list(launcher) + [\n",
    "        \"fullrun.py\",\n",
    "        \"--out\",\n",
    "        str(out_dir_rel),\n",
    "    ]\n",
    "    if w_resume.value:\n",
    "        cmd.append(\"--resume\")\n",
    "    cmd += [\"--methods\", \",\".join(methods)]\n",
    "    if w_dry_run.value:\n",
    "        cmd.append(\"--dry-run\")\n",
    "\n",
    "    return {\n",
    "        \"timestamp_utc\": _utc_now_iso(),\n",
    "        \"repo_root\": str(repo_root),\n",
    "        \"out_dir_rel\": str(out_dir_rel),\n",
    "        \"out_dir\": str(out_dir_abs),\n",
    "        \"command_list\": cmd,\n",
    "        \"command_string\": subprocess.list2cmdline([str(x) for x in cmd]),\n",
    "        \"methods\": methods,\n",
    "        \"resume\": bool(w_resume.value),\n",
    "        \"dry_run\": bool(w_dry_run.value),\n",
    "        \"sys_executable\": sys.executable,\n",
    "        \"python_version\": sys.version.split()[0],\n",
    "        \"conda_default_env\": os.environ.get(\"CONDA_DEFAULT_ENV\"),\n",
    "        \"platform\": {\n",
    "            \"os_name\": os.name,\n",
    "            \"sys_platform\": sys.platform,\n",
    "        },\n",
    "        \"launcher\": launcher,\n",
    "    }\n",
    "\n",
    "\n",
    "def _render_plan_preview():\n",
    "    with out_plan:\n",
    "        clear_output()\n",
    "        try:\n",
    "            spec = build_plan_spec()\n",
    "        except Exception as e:\n",
    "            display(_html_box(f\"Plan ist aktuell nicht valide: {type(e).__name__}: {e}\", kind=\"error\"))\n",
    "            return\n",
    "\n",
    "        out_dir_rel = spec[\"out_dir_rel\"]\n",
    "        out_dir_abs = spec[\"out_dir\"]\n",
    "        print(\"Out-Ordner (rel):\", out_dir_rel)\n",
    "        print(\"Out-Ordner (abs):\", out_dir_abs)\n",
    "        print(\"\\nBefehl (Liste):\")\n",
    "        print(spec[\"command_list\"])\n",
    "        print(\"\\nBefehl (String):\")\n",
    "        print(spec[\"command_string\"])\n",
    "\n",
    "        display(_html_box(\"OK: Plan ist valide.\", kind=\"ok\"))\n",
    "\n",
    "\n",
    "def _on_validate(_):\n",
    "    with out_plan:\n",
    "        print(\"\\n[Validieren] fullrun.py --help ...\")\n",
    "        try:\n",
    "            launcher = _build_python_launcher()\n",
    "            if launcher[:1] == [\"conda\"] and shutil.which(\"conda\") is None:\n",
    "                raise FileNotFoundError(\"'conda' nicht auf PATH (conda-run ist aktiv).\")\n",
    "            cmd = list(launcher) + [\"fullrun.py\", \"--help\"]\n",
    "            r = subprocess.run(\n",
    "                cmd,\n",
    "                cwd=str(repo_root),\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                encoding=\"utf-8\",\n",
    "                errors=\"replace\",\n",
    "                timeout=10,\n",
    "            )\n",
    "            if r.returncode == 0:\n",
    "                display(_html_box(\"Validieren OK: fullrun.py --help erfolgreich.\", kind=\"ok\"))\n",
    "                lines = (r.stdout or \"\").splitlines()[:25]\n",
    "                print(\"\\n\".join(lines))\n",
    "            else:\n",
    "                display(_html_box(f\"Validieren fehlgeschlagen: Exitcode {r.returncode}\", kind=\"error\"))\n",
    "                print((r.stdout or \"\").strip())\n",
    "                print((r.stderr or \"\").strip())\n",
    "        except Exception as e:\n",
    "            display(_html_box(f\"Validieren: {type(e).__name__}: {e}\", kind=\"error\"))\n",
    "\n",
    "\n",
    "def write_plan(spec: dict, *, overwrite: bool = False) -> Path:\n",
    "    out_dir_abs = Path(spec[\"out_dir\"])  # abs\n",
    "    out_dir_abs.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plan_path = out_dir_abs / \"plan.json\"\n",
    "    if plan_path.exists() and not overwrite:\n",
    "        # Guard: nicht stillschweigend überschreiben\n",
    "        return plan_path\n",
    "\n",
    "    commit_hash, git_dirty, note = _git_snapshot(repo_root)\n",
    "    spec = dict(spec)\n",
    "    spec[\"commit_hash\"] = commit_hash\n",
    "    spec[\"git_dirty\"] = git_dirty\n",
    "    spec[\"git_note\"] = note\n",
    "\n",
    "    plan_path.write_text(json.dumps(spec, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    return plan_path\n",
    "\n",
    "\n",
    "def _on_write_plan(_):\n",
    "    with out_plan:\n",
    "        print(\"\\n[Plan schreiben] ...\")\n",
    "        try:\n",
    "            now = datetime.datetime.now()\n",
    "            spec = build_plan_spec(now=now)\n",
    "            plan_path = write_plan(spec, overwrite=False)\n",
    "            if plan_path.exists():\n",
    "                display(_html_box(f\"Plan geschrieben: {plan_path}\", kind=\"ok\"))\n",
    "            else:\n",
    "                display(_html_box(\"Plan konnte nicht geschrieben werden (unerwartet).\", kind=\"error\"))\n",
    "\n",
    "            # globaler Snapshot für spätere Zellen\n",
    "            globals()[\"LAST_PLAN_PATH\"] = str(plan_path)\n",
    "            globals()[\"LAST_OUT_DIR\"] = str(Path(spec[\"out_dir\"]))\n",
    "        except Exception as e:\n",
    "            display(_html_box(f\"Plan schreiben: {type(e).__name__}: {e}\", kind=\"error\"))\n",
    "\n",
    "\n",
    "btn_validate.on_click(_on_validate)\n",
    "btn_write_plan.on_click(_on_write_plan)\n",
    "\n",
    "ui_left = widgets.VBox([w_base_out, w_label, w_methods])\n",
    "ui_right = widgets.VBox([w_timestamped, w_resume, w_dry_run, w_conda_run, w_conda_env])\n",
    "ui_buttons = widgets.HBox([btn_validate, btn_write_plan])\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([ui_left, ui_right]), ui_buttons, out_plan]))\n",
    "\n",
    "\n",
    "# Preview automatisch aktualisieren\n",
    "for w in [w_base_out, w_timestamped, w_label, w_resume, w_dry_run, w_methods, w_conda_run, w_conda_env]:\n",
    "    w.observe(lambda _chg: _render_plan_preview(), names=\"value\")\n",
    "\n",
    "_render_plan_preview()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "run-md",
   "metadata": {},
   "source": [
    "## 4) AUSFÜHRUNG (Live-Ausgabe)\n",
    "\n",
    "Der Startknopf startet den Subprozess (ohne `shell=True`) und streamt stdout/stderr live. Zusätzlich wird `notebook_run.log` in den Ausgabeordner geschrieben.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "run-code",
   "metadata": {},
   "source": [
    "btn_run_now = widgets.Button(description=\"Run starten\", button_style=\"danger\")\n",
    "out_run = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\", max_height=\"380px\", overflow=\"auto\"))\n",
    "\n",
    "\n",
    "def _ensure_plan_for_run(spec: dict) -> Path:\n",
    "    out_dir_abs = Path(spec[\"out_dir\"])  # abs\n",
    "    plan_path = out_dir_abs / \"plan.json\"\n",
    "    if plan_path.exists():\n",
    "        # Prüfe grob, ob der Plan zur aktuellen Spec passt (falls nicht: lieber abbrechen)\n",
    "        try:\n",
    "            old = json.loads(plan_path.read_text(encoding=\"utf-8\"))\n",
    "            if old.get(\"command_list\") != spec.get(\"command_list\"):\n",
    "                raise RuntimeError(\n",
    "                    \"plan.json existiert bereits, aber passt nicht zur aktuellen Planung.\\n\"\n",
    "                    \"Tipp: Nutze ein neues Label oder aktiviere 'Timestamped Out-Ordner'.\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            raise\n",
    "        return plan_path\n",
    "    return write_plan(spec, overwrite=False)\n",
    "\n",
    "\n",
    "def _on_run_now(_):\n",
    "    btn_run_now.disabled = True\n",
    "    try:\n",
    "        with out_run:\n",
    "            clear_output()\n",
    "            print(\"[Ausführung] Starte Subprozess ...\")\n",
    "\n",
    "        now = datetime.datetime.now()\n",
    "        spec = build_plan_spec(now=now)\n",
    "        out_dir_abs = Path(spec[\"out_dir\"])  # abs\n",
    "        cmd = [str(x) for x in spec[\"command_list\"]]\n",
    "\n",
    "        plan_path = _ensure_plan_for_run(spec)\n",
    "\n",
    "        log_path = out_dir_abs / \"notebook_run.log\"\n",
    "        start_t = time.monotonic()\n",
    "\n",
    "        env = os.environ.copy()\n",
    "        env[\"PYTHONUNBUFFERED\"] = \"1\"\n",
    "        env[\"PYTHONIOENCODING\"] = \"utf-8\"\n",
    "\n",
    "        with log_path.open(\"w\", encoding=\"utf-8\", errors=\"replace\") as log_f:\n",
    "            with out_run:\n",
    "                print(\"Out-Ordner:\", out_dir_abs)\n",
    "                print(\"Plan:\", plan_path)\n",
    "                print(\"Befehl:\")\n",
    "                print(spec[\"command_string\"])\n",
    "                print(\"\\n--- Live-Output ---\\n\")\n",
    "\n",
    "            proc = subprocess.Popen(\n",
    "                cmd,\n",
    "                cwd=str(repo_root),\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                encoding=\"utf-8\",\n",
    "                errors=\"replace\",\n",
    "                bufsize=1,\n",
    "                shell=False,\n",
    "                env=env,\n",
    "            )\n",
    "\n",
    "            assert proc.stdout is not None\n",
    "            for line in proc.stdout:\n",
    "                log_f.write(line)\n",
    "                log_f.flush()\n",
    "                out_run.append_stdout(line)\n",
    "\n",
    "            rc = int(proc.wait())\n",
    "            dur = time.monotonic() - start_t\n",
    "\n",
    "        with out_run:\n",
    "            print(\"\\n--- Fertig ---\")\n",
    "            print(\"Exitcode:\", rc)\n",
    "            print(\"Laufzeit (s):\", round(dur, 2))\n",
    "            print(\"Log:\", log_path)\n",
    "\n",
    "        globals()[\"LAST_RUN_DIR\"] = str(out_dir_abs)\n",
    "\n",
    "        # Optional: Report-Dropdown (falls bereits gebaut) auf diesen Run setzen\n",
    "        if rc == 0 and \"refresh_run_options\" in globals() and \"w_run_select\" in globals():\n",
    "            try:\n",
    "                refresh_run_options()\n",
    "                w_run_select.value = str(out_dir_abs)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    except Exception as e:\n",
    "        with out_run:\n",
    "            display(_html_box(f\"RUN ERROR: {type(e).__name__}: {e}\", kind=\"error\"))\n",
    "    finally:\n",
    "        btn_run_now.disabled = False\n",
    "\n",
    "\n",
    "btn_run_now.on_click(_on_run_now)\n",
    "display(widgets.VBox([btn_run_now, out_run]))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "report-md",
   "metadata": {},
   "source": [
    "## 5) Bericht (Lauf auswählen + Überblick)\n",
    "\n",
    "Hier werden die Ausgaben aus `stage3_evaluation/` eines ausgewählten Laufs geladen (CSV + Metadaten). Die zentrale Datei ist `stage3_evaluation/aggregated_metrics.csv`; wenn sie fehlt, ist Etappe 03 meistens noch nicht durchgelaufen.\n",
    "\n",
    "Je nach Run können zusätzlich z. B. `per_instance_metrics.csv`, `coverage_matrix_aggregated.csv` oder `winrate_heatmap.csv` auftauchen.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "report-code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "out_report = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "btn_refresh_runs = widgets.Button(description=\"Runs aktualisieren\", button_style=\"info\")\n",
    "\n",
    "\n",
    "def _read_json(path: Path) -> dict | None:\n",
    "    try:\n",
    "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _find_run_roots() -> list[Path]:\n",
    "    roots = []\n",
    "\n",
    "    # Fixe Anforderungen aus Kap. 5 (Methodisches Vorgehen)\n",
    "    runs_root = (repo_root / \"runs\").resolve()\n",
    "    if runs_root.exists():\n",
    "        for p in runs_root.rglob(\"aggregated_metrics.csv\"):\n",
    "            if p.parent.name == \"stage3_evaluation\":\n",
    "                roots.append(p.parent.parent)\n",
    "\n",
    "    fullrun_out_root = (repo_root / \"fullrun_out\").resolve()\n",
    "    p = fullrun_out_root / \"stage3_evaluation\" / \"aggregated_metrics.csv\"\n",
    "    if p.exists():\n",
    "        roots.append(fullrun_out_root)\n",
    "\n",
    "    # Optional: falls Out-Basis anders gesetzt ist\n",
    "    try:\n",
    "        base_out = Path((w_base_out.value or \"\").strip())\n",
    "        if str(base_out) and str(base_out) != \"runs\":\n",
    "            base_root = (repo_root / base_out).resolve()\n",
    "            if base_root.exists():\n",
    "                for p in base_root.rglob(\"aggregated_metrics.csv\"):\n",
    "                    if p.parent.name == \"stage3_evaluation\":\n",
    "                        roots.append(p.parent.parent)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Dedupe + sort (neueste zuerst, falls timestamped-Ordner)\n",
    "    uniq = []\n",
    "    seen = set()\n",
    "    for r in roots:\n",
    "        s = str(r)\n",
    "        if s in seen:\n",
    "            continue\n",
    "        seen.add(s)\n",
    "        uniq.append(r)\n",
    "    uniq.sort(key=lambda p: p.name, reverse=True)\n",
    "    return uniq\n",
    "\n",
    "\n",
    "def refresh_run_options():\n",
    "    run_roots = _find_run_roots()\n",
    "    options = []\n",
    "    for r in run_roots:\n",
    "        try:\n",
    "            rel = r.relative_to(repo_root)\n",
    "            label = str(rel)\n",
    "        except Exception:\n",
    "            label = str(r)\n",
    "        options.append((label, str(r)))\n",
    "\n",
    "    if not options:\n",
    "        options = [(\"(keine Runs gefunden)\", \"\")]\n",
    "\n",
    "    w_run_select.options = options\n",
    "    # Auto-select: letzter Run aus Run-Zelle\n",
    "    last = globals().get(\"LAST_RUN_DIR\")\n",
    "    if last and any(v == last for _lbl, v in options):\n",
    "        w_run_select.value = last\n",
    "\n",
    "\n",
    "w_run_select = widgets.Dropdown(options=[(\"(lade...)\", \"\")], description=\"Run auswählen\", layout=widgets.Layout(width=\"720px\"))\n",
    "\n",
    "\n",
    "def _report_for_run(run_root: Path):\n",
    "    stage3_dir = run_root / \"stage3_evaluation\"\n",
    "    agg_path = stage3_dir / \"aggregated_metrics.csv\"\n",
    "    if not agg_path.exists():\n",
    "        display(_html_box(f\"Fehlt: {agg_path}\", kind=\"error\"))\n",
    "        return\n",
    "\n",
    "    plan = _read_json(run_root / \"plan.json\")\n",
    "    meta = _read_json(run_root / \"metadata.json\") or _read_json(stage3_dir / \"metadata.json\")\n",
    "\n",
    "    # Repro Snapshot\n",
    "    commit_hash = None\n",
    "    git_dirty = None\n",
    "    methods = None\n",
    "    ts = None\n",
    "    cmd_str = None\n",
    "\n",
    "    if isinstance(plan, dict):\n",
    "        commit_hash = plan.get(\"commit_hash\")\n",
    "        git_dirty = plan.get(\"git_dirty\")\n",
    "        methods = plan.get(\"methods\")\n",
    "        ts = plan.get(\"timestamp_utc\")\n",
    "        cmd_str = plan.get(\"command_string\")\n",
    "\n",
    "    if isinstance(meta, dict):\n",
    "        commit_hash = commit_hash or meta.get(\"git_commit\")\n",
    "        ts = ts or meta.get(\"timestamp_utc\")\n",
    "        cli_args = meta.get(\"cli_args\") if isinstance(meta.get(\"cli_args\"), dict) else None\n",
    "        if cli_args:\n",
    "            methods = methods if methods is not None else cli_args.get(\"methods\")\n",
    "        if cmd_str is None and isinstance(meta.get(\"argv\"), list):\n",
    "            cmd_str = \" \".join(str(x) for x in meta.get(\"argv\"))\n",
    "\n",
    "    snapshot_lines = [\n",
    "        f\"Run: {run_root}\",\n",
    "        f\"timestamp: {ts}\",\n",
    "        f\"commit_hash: {commit_hash}\",\n",
    "        f\"git_dirty: {git_dirty}\",\n",
    "        f\"methods: {methods}\",\n",
    "    ]\n",
    "    if cmd_str:\n",
    "        snapshot_lines.append(f\"command: {cmd_str}\")\n",
    "    display(_html_box(\"Repro Snapshot\\n\" + \"\\n\".join(snapshot_lines), kind=\"info\"))\n",
    "\n",
    "    # aggregated_metrics.csv (Pflicht)\n",
    "    df_agg = pd.read_csv(agg_path)\n",
    "\n",
    "    df_view = df_agg\n",
    "    if \"size_class\" in df_view.columns and (df_view[\"size_class\"].astype(str).str.lower() == \"all\").any():\n",
    "        df_view = df_view[df_view[\"size_class\"].astype(str).str.lower() == \"all\"]\n",
    "    if \"severity\" in df_view.columns and (df_view[\"severity\"].astype(str).str.lower() == \"all\").any():\n",
    "        df_view = df_view[df_view[\"severity\"].astype(str).str.lower() == \"all\"]\n",
    "\n",
    "    display(HTML(\"<h4>Aggregated Metrics (Global)</h4>\"))\n",
    "    if df_view.empty:\n",
    "        display(df_agg.head(20))\n",
    "    else:\n",
    "        # kompakter View\n",
    "        cols = [c for c in [\n",
    "            \"size_class\",\n",
    "            \"severity\",\n",
    "            \"method\",\n",
    "            \"n_is\",\n",
    "            \"nd_size_median\",\n",
    "            \"contrib_unique_median\",\n",
    "            \"runtime_median_seconds_median\",\n",
    "            \"ttff_median_seconds_median\",\n",
    "            \"feasibility_rate_median\",\n",
    "        ] if c in df_view.columns]\n",
    "        display(df_view[cols].reset_index(drop=True))\n",
    "\n",
    "    # per_instance_metrics.csv (optional)\n",
    "    per_path = stage3_dir / \"per_instance_metrics.csv\"\n",
    "    if per_path.exists():\n",
    "        df_per = pd.read_csv(per_path)\n",
    "        if {\"method\", \"nd_size\", \"runtime_median_seconds\"}.issubset(df_per.columns):\n",
    "            display(HTML(\"<h4>Per-Instance Boxplots</h4>\"))\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "            df_per.boxplot(column=\"nd_size\", by=\"method\", ax=axes[0])\n",
    "            axes[0].set_title(\"ND size\")\n",
    "            axes[0].set_xlabel(\"Verfahren\")\n",
    "            axes[0].set_ylabel(\"nd_size\")\n",
    "\n",
    "            df_per.boxplot(column=\"runtime_median_seconds\", by=\"method\", ax=axes[1])\n",
    "            axes[1].set_title(\"Runtime median (s)\")\n",
    "            axes[1].set_xlabel(\"Verfahren\")\n",
    "            axes[1].set_ylabel(\"seconds\")\n",
    "\n",
    "            fig.suptitle(\"\")\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            display(_html_box(f\"Spalten in per_instance_metrics unerwartet: {list(df_per.columns)}\", kind=\"warn\"))\n",
    "    else:\n",
    "        display(_html_box(\"Optional fehlt: per_instance_metrics.csv\", kind=\"info\"))\n",
    "\n",
    "    # coverage_matrix_aggregated.csv (optional)\n",
    "    cov_path = stage3_dir / \"coverage_matrix_aggregated.csv\"\n",
    "    if cov_path.exists():\n",
    "        df_cov = pd.read_csv(cov_path)\n",
    "        needed = {\"method_a\", \"method_b\", \"coverage_median\"}\n",
    "        if needed.issubset(df_cov.columns):\n",
    "            df_cov_view = df_cov\n",
    "            if \"size_class\" in df_cov_view.columns and (df_cov_view[\"size_class\"].astype(str).str.lower() == \"all\").any():\n",
    "                df_cov_view = df_cov_view[df_cov_view[\"size_class\"].astype(str).str.lower() == \"all\"]\n",
    "            if \"severity\" in df_cov_view.columns and (df_cov_view[\"severity\"].astype(str).str.lower() == \"all\").any():\n",
    "                df_cov_view = df_cov_view[df_cov_view[\"severity\"].astype(str).str.lower() == \"all\"]\n",
    "\n",
    "            pivot = df_cov_view.pivot(index=\"method_a\", columns=\"method_b\", values=\"coverage_median\")\n",
    "            pivot = pivot.reindex(index=sorted(pivot.index), columns=sorted(pivot.columns))\n",
    "\n",
    "            display(HTML(\"<h4>Coverage Heatmap (Median)</h4>\"))\n",
    "            plt.figure(figsize=(5.5, 4.5))\n",
    "            plt.imshow(pivot.values, cmap=\"viridis\", vmin=0, vmax=1)\n",
    "            plt.xticks(range(len(pivot.columns)), pivot.columns)\n",
    "            plt.yticks(range(len(pivot.index)), pivot.index)\n",
    "            plt.colorbar(label=\"C(A,B)\")\n",
    "            plt.title(\"Coverage (Median)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            display(_html_box(f\"coverage_matrix_aggregated Spalten unerwartet: {list(df_cov.columns)}\", kind=\"warn\"))\n",
    "    else:\n",
    "        display(_html_box(\"Optional fehlt: coverage_matrix_aggregated.csv\", kind=\"info\"))\n",
    "\n",
    "    # winrate_heatmap.csv (optional)\n",
    "    win_path = stage3_dir / \"winrate_heatmap.csv\"\n",
    "    if win_path.exists():\n",
    "        df_win = pd.read_csv(win_path)\n",
    "        needed = {\"omega\", \"method\", \"win_rate\"}\n",
    "        if needed.issubset(df_win.columns):\n",
    "            pivot = df_win.pivot(index=\"omega\", columns=\"method\", values=\"win_rate\")\n",
    "            pivot = pivot.reindex(columns=sorted(pivot.columns))\n",
    "            # stabile Reihenfolge der omegas: lexikografisch\n",
    "            pivot = pivot.sort_index()\n",
    "\n",
    "            display(HTML(\"<h4>Win-Rate Heatmap</h4>\"))\n",
    "            h = max(4.0, min(10.0, 0.25 * len(pivot.index)))\n",
    "            plt.figure(figsize=(6.5, h))\n",
    "            plt.imshow(pivot.values, cmap=\"magma\", vmin=0, vmax=1, aspect=\"auto\")\n",
    "            plt.xticks(range(len(pivot.columns)), pivot.columns)\n",
    "            plt.yticks(range(len(pivot.index)), pivot.index, fontsize=7)\n",
    "            plt.colorbar(label=\"win_rate\")\n",
    "            plt.title(\"Win-Rate je ω\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            display(_html_box(f\"winrate_heatmap Spalten unerwartet: {list(df_win.columns)}\", kind=\"warn\"))\n",
    "    else:\n",
    "        display(_html_box(\"Optional fehlt: winrate_heatmap.csv\", kind=\"info\"))\n",
    "\n",
    "    globals()[\"SELECTED_RUN_ROOT\"] = str(run_root)\n",
    "\n",
    "\n",
    "def _on_run_select_change(_):\n",
    "    with out_report:\n",
    "        clear_output()\n",
    "        val = str(w_run_select.value or \"\").strip()\n",
    "        if not val:\n",
    "            display(_html_box(\"Kein Run ausgewählt.\", kind=\"warn\"))\n",
    "            return\n",
    "        run_root = Path(val)\n",
    "        _report_for_run(run_root)\n",
    "\n",
    "\n",
    "def _on_refresh(_):\n",
    "    refresh_run_options()\n",
    "\n",
    "\n",
    "btn_refresh_runs.on_click(_on_refresh)\n",
    "w_run_select.observe(_on_run_select_change, names=\"value\")\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([btn_refresh_runs, w_run_select]), out_report]))\n",
    "refresh_run_options()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "figures-md",
   "metadata": {},
   "source": [
    "## 6) Abbildungen (Browser)\n",
    "\n",
    "Anzeige von PDFs aus `stage3_evaluation/figures/`. Standardmäßig werden sie per IFrame eingebettet (plus Link). Wenn `fitz` (PyMuPDF) installiert ist, rendert das Notebook alternativ Seiten als Bilder (mit Vor/Zurück).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "figures-code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out_fig = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "btn_refresh_fig = widgets.Button(description=\"Abbildungen aktualisieren\", button_style=\"info\")\n",
    "w_pdf_select = widgets.Dropdown(options=[(\"(kein Run geladen)\", \"\")], description=\"PDF\", layout=widgets.Layout(width=\"720px\"))\n",
    "\n",
    "btn_prev = widgets.Button(description=\"Vorherige Seite\")\n",
    "btn_next = widgets.Button(description=\"Nächste Seite\")\n",
    "w_page = widgets.IntText(value=0, description=\"Seite\", layout=widgets.Layout(width=\"200px\"))\n",
    "\n",
    "\n",
    "def _get_selected_run_root() -> Path | None:\n",
    "    val = globals().get(\"SELECTED_RUN_ROOT\")\n",
    "    if not val:\n",
    "        return None\n",
    "    p = Path(str(val))\n",
    "    return p if p.exists() else None\n",
    "\n",
    "\n",
    "def _list_pdfs(run_root: Path) -> list[Path]:\n",
    "    fig_dir = run_root / \"stage3_evaluation\" / \"figures\"\n",
    "    if not fig_dir.exists():\n",
    "        return []\n",
    "    return sorted(fig_dir.glob(\"*.pdf\"))\n",
    "\n",
    "\n",
    "def refresh_figures():\n",
    "    run_root = _get_selected_run_root()\n",
    "    if run_root is None:\n",
    "        w_pdf_select.options = [(\"(kein Run geladen)\", \"\")]\n",
    "        w_pdf_select.value = \"\"\n",
    "        return\n",
    "\n",
    "    pdfs = _list_pdfs(run_root)\n",
    "    if not pdfs:\n",
    "        w_pdf_select.options = [(\"(keine PDFs gefunden)\", \"\")]\n",
    "        w_pdf_select.value = \"\"\n",
    "        return\n",
    "\n",
    "    options = []\n",
    "    for p in pdfs:\n",
    "        options.append((p.name, str(p)))\n",
    "    w_pdf_select.options = options\n",
    "    if not w_pdf_select.value:\n",
    "        w_pdf_select.value = options[0][1]\n",
    "\n",
    "\n",
    "def _render_pdf_preview(pdf_path: Path, page_index: int = 0):\n",
    "    # Erst fitz versuchen\n",
    "    try:\n",
    "        import fitz  # type: ignore\n",
    "\n",
    "        doc = fitz.open(pdf_path)\n",
    "        if doc.page_count <= 0:\n",
    "            display(_html_box(\"PDF hat keine Seiten.\", kind=\"warn\"))\n",
    "            return\n",
    "        page_index = max(0, min(int(page_index), doc.page_count - 1))\n",
    "        page = doc.load_page(page_index)\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2), alpha=False)\n",
    "        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"{pdf_path.name} (page {page_index+1}/{doc.page_count})\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: IFrame + Link\n",
    "    try:\n",
    "        rel = pdf_path\n",
    "        try:\n",
    "            rel = pdf_path.relative_to(repo_root)\n",
    "        except Exception:\n",
    "            rel = pdf_path\n",
    "\n",
    "        display(_html_box(\"fitz nicht verfügbar -> IFrame/Link-Fallback.\", kind=\"info\"))\n",
    "        src = rel.as_posix()\n",
    "        display(IFrame(src=src, width=950, height=600))\n",
    "        display(HTML(f\"<a href='{src}' target='_blank'>PDF öffnen: {pdf_path.name}</a>\"))\n",
    "    except Exception as e:\n",
    "        display(_html_box(f\"PDF Anzeige fehlgeschlagen: {type(e).__name__}: {e}\", kind=\"error\"))\n",
    "\n",
    "\n",
    "def _on_pdf_change(_):\n",
    "    with out_fig:\n",
    "        clear_output()\n",
    "        val = str(w_pdf_select.value or \"\").strip()\n",
    "        if not val:\n",
    "            display(_html_box(\"Kein PDF gewählt.\", kind=\"warn\"))\n",
    "            return\n",
    "        pdf_path = Path(val)\n",
    "        if not pdf_path.exists():\n",
    "            display(_html_box(f\"PDF existiert nicht: {pdf_path}\", kind=\"error\"))\n",
    "            return\n",
    "        _render_pdf_preview(pdf_path, page_index=int(w_page.value))\n",
    "\n",
    "\n",
    "def _on_prev(_):\n",
    "    w_page.value = max(0, int(w_page.value) - 1)\n",
    "    _on_pdf_change(None)\n",
    "\n",
    "\n",
    "def _on_next(_):\n",
    "    w_page.value = int(w_page.value) + 1\n",
    "    _on_pdf_change(None)\n",
    "\n",
    "\n",
    "btn_refresh_fig.on_click(lambda _: refresh_figures())\n",
    "w_pdf_select.observe(_on_pdf_change, names=\"value\")\n",
    "btn_prev.on_click(_on_prev)\n",
    "btn_next.on_click(_on_next)\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([btn_refresh_fig, w_pdf_select]), widgets.HBox([btn_prev, btn_next, w_page]), out_fig]))\n",
    "refresh_figures()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "sanity-md",
   "metadata": {},
   "source": [
    "## 7) Kurzchecks\n",
    "\n",
    "Hier werden `stage2_runs/**/runs.jsonl` und `stage2_runs/**/solutions.jsonl` grob geprüft (z. B. Zeilenzahl in `solutions.jsonl` als `n_solutions`, Warnungen bei leeren/fehlenden Dateien). Wenn `stage3_evaluation/milp_subruns.csv` existiert, zeigt das Notebook zusätzlich die Häufigkeiten der `termination_reason`.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "sanity-code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "btn_sanity = widgets.Button(description=\"Sanity-Checks ausführen\", button_style=\"warning\")\n",
    "out_sanity = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "\n",
    "\n",
    "def _count_lines(path: Path) -> int:\n",
    "    n = 0\n",
    "    with path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for _ in f:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "def _on_sanity(_):\n",
    "    with out_sanity:\n",
    "        clear_output()\n",
    "        run_root = _get_selected_run_root()\n",
    "        if run_root is None:\n",
    "            display(_html_box(\"Kein Run ausgewählt (Report zuerst laden).\", kind=\"warn\"))\n",
    "            return\n",
    "\n",
    "        stage2_dir = run_root / \"stage2_runs\"\n",
    "        if not stage2_dir.exists():\n",
    "            display(_html_box(f\"Fehlt: {stage2_dir}\", kind=\"error\"))\n",
    "            return\n",
    "\n",
    "        rows = []\n",
    "        for sol_path in stage2_dir.rglob(\"solutions.jsonl\"):\n",
    "            try:\n",
    "                rel = sol_path.relative_to(stage2_dir)\n",
    "                parts = rel.parts\n",
    "                dataset_id = parts[0] if len(parts) >= 1 else \"?\"\n",
    "                case_id = parts[1] if len(parts) >= 2 else \"?\"\n",
    "                method = parts[2] if len(parts) >= 3 else \"?\"\n",
    "            except Exception:\n",
    "                dataset_id, case_id, method = \"?\", \"?\", \"?\"\n",
    "\n",
    "            run_path = sol_path.with_name(\"runs.jsonl\")\n",
    "            n_sol = _count_lines(sol_path)\n",
    "            n_run = _count_lines(run_path) if run_path.exists() else None\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"dataset_id\": dataset_id,\n",
    "                    \"case_id\": case_id,\n",
    "                    \"method\": method,\n",
    "                    \"n_solutions\": n_sol,\n",
    "                    \"n_runs\": n_run,\n",
    "                    \"solutions_path\": str(sol_path),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if not rows:\n",
    "            display(_html_box(\"Keine solutions.jsonl gefunden.\", kind=\"warn\"))\n",
    "        else:\n",
    "            df = pd.DataFrame(rows)\n",
    "            display(HTML(\"<h4>Stage 2 Artefakte</h4>\"))\n",
    "            display(df.sort_values([\"dataset_id\", \"case_id\", \"method\"]).reset_index(drop=True))\n",
    "\n",
    "            display(HTML(\"<h4>Warnungen</h4>\"))\n",
    "            bad = df[df[\"n_solutions\"] <= 0]\n",
    "            if bad.empty:\n",
    "                display(_html_box(\"OK: Keine leeren solutions.jsonl.\", kind=\"ok\"))\n",
    "            else:\n",
    "                display(_html_box(f\"WARN: {len(bad)} Dateien haben 0 Lösungen.\", kind=\"warn\"))\n",
    "                display(bad[[\"dataset_id\", \"case_id\", \"method\", \"n_solutions\", \"solutions_path\"]])\n",
    "\n",
    "            display(HTML(\"<h4>Überblick pro Verfahren</h4>\"))\n",
    "            display(df.groupby(\"method\")[\"n_solutions\"].agg([\"count\", \"min\", \"median\", \"max\", \"sum\"]))\n",
    "\n",
    "        # Optional: MILP subruns termination reasons\n",
    "        milp_path = run_root / \"stage3_evaluation\" / \"milp_subruns.csv\"\n",
    "        if milp_path.exists():\n",
    "            df_m = pd.read_csv(milp_path)\n",
    "            display(HTML(\"<h4>MILP Subruns</h4>\"))\n",
    "            if \"termination_reason\" in df_m.columns:\n",
    "                display(df_m[\"termination_reason\"].value_counts(dropna=False).to_frame(\"count\"))\n",
    "            else:\n",
    "                display(_html_box(f\"Spalte termination_reason fehlt. Spalten: {list(df_m.columns)}\", kind=\"warn\"))\n",
    "        else:\n",
    "            display(_html_box(\"Optional fehlt: stage3_evaluation/milp_subruns.csv\", kind=\"info\"))\n",
    "\n",
    "\n",
    "btn_sanity.on_click(_on_sanity)\n",
    "display(widgets.VBox([btn_sanity, out_sanity]))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "export-md",
   "metadata": {},
   "source": [
    "## 8) EXPORT (LaTeX-Assets)\n",
    "\n",
    "Zielordner ist `thesis_assets/<run_name>/`. Von dort aus kann ich die Tabellen/Abbildungen später im LaTeX-Projekt referenzieren, ohne auf Zwischenstände in `fullrun_out/...` zu zeigen.\n",
    "\n",
    "Je nach Auswahl kopiert das Notebook:\n",
    "- `stage3_evaluation/tables/*.tex` nach `thesis_assets/.../tables/`\n",
    "- ausgewählte PDFs nach `thesis_assets/.../figures/`\n",
    "- ausgewählte CSVs nach `thesis_assets/.../csv/`\n",
    "\n",
    "Zur Nachvollziehbarkeit wird zusätzlich eine `EXPORT_MANIFEST.json` geschrieben (Quelle, Timestamp, Commit/git_dirty, kopierte Dateien).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "export-code",
   "metadata": {},
   "source": [
    "btn_export_tables = widgets.Button(description=\"LaTeX-Tabellen exportieren\", button_style=\"success\")\n",
    "btn_export_figs = widgets.Button(description=\"Schlüsselabbildungen exportieren\", button_style=\"success\")\n",
    "btn_export_csv = widgets.Button(description=\"CSVs exportieren\", button_style=\"success\")\n",
    "out_export = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "\n",
    "w_is_select = widgets.Dropdown(options=[(\"(auto)\", \"\")], description=\"Instanz\", layout=widgets.Layout(width=\"720px\"))\n",
    "btn_refresh_is = widgets.Button(description=\"Instanzen aktualisieren\", button_style=\"info\")\n",
    "\n",
    "\n",
    "def _git_snapshot_now(cwd: Path) -> dict:\n",
    "    \"\"\"Git-Snapshot zum Export-Zeitpunkt (Fallback, falls plan.json fehlt).\"\"\"\n",
    "    commit_hash = None\n",
    "    git_dirty = None\n",
    "    note = None\n",
    "\n",
    "    try:\n",
    "        r1 = subprocess.run(\n",
    "            [\"git\", \"rev-parse\", \"HEAD\"],\n",
    "            cwd=str(cwd),\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            encoding=\"utf-8\",\n",
    "            errors=\"replace\",\n",
    "            timeout=5,\n",
    "        )\n",
    "        if r1.returncode == 0:\n",
    "            commit_hash = (r1.stdout or \"\").strip() or None\n",
    "        else:\n",
    "            note = (r1.stderr or r1.stdout or \"\").strip() or \"git rev-parse fehlgeschlagen\"\n",
    "\n",
    "        r2 = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\"],\n",
    "            cwd=str(cwd),\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            encoding=\"utf-8\",\n",
    "            errors=\"replace\",\n",
    "            timeout=5,\n",
    "        )\n",
    "        if r2.returncode == 0:\n",
    "            git_dirty = bool((r2.stdout or \"\").strip())\n",
    "        else:\n",
    "            if note is None:\n",
    "                note = (r2.stderr or r2.stdout or \"\").strip() or \"git status fehlgeschlagen\"\n",
    "    except FileNotFoundError:\n",
    "        note = \"git unavailable\"\n",
    "    except Exception as e:\n",
    "        note = f\"git error: {type(e).__name__}: {e}\"\n",
    "\n",
    "    return {\n",
    "        \"commit_hash\": commit_hash,\n",
    "        \"git_dirty\": git_dirty,\n",
    "        \"git_note\": note,\n",
    "    }\n",
    "\n",
    "\n",
    "def _load_repro_from_run(run_root: Path) -> dict:\n",
    "    plan = _read_json(run_root / \"plan.json\")\n",
    "    meta = _read_json(run_root / \"metadata.json\") or _read_json(run_root / \"stage3_evaluation\" / \"metadata.json\")\n",
    "\n",
    "    commit_hash = None\n",
    "    git_dirty = None\n",
    "    methods = None\n",
    "\n",
    "    if isinstance(plan, dict):\n",
    "        commit_hash = plan.get(\"commit_hash\")\n",
    "        git_dirty = plan.get(\"git_dirty\")\n",
    "        methods = plan.get(\"methods\")\n",
    "\n",
    "    if isinstance(meta, dict):\n",
    "        commit_hash = commit_hash or meta.get(\"git_commit\")\n",
    "        cli_args = meta.get(\"cli_args\") if isinstance(meta.get(\"cli_args\"), dict) else None\n",
    "        if cli_args:\n",
    "            methods = methods if methods is not None else cli_args.get(\"methods\")\n",
    "\n",
    "    return {\n",
    "        \"commit_hash\": commit_hash,\n",
    "        \"git_dirty\": git_dirty,\n",
    "        \"methods\": methods,\n",
    "    }\n",
    "\n",
    "\n",
    "def _export_root_for_run(run_root: Path) -> Path:\n",
    "    run_name = run_root.name\n",
    "    return (repo_root / \"thesis_assets\" / run_name).resolve()\n",
    "\n",
    "\n",
    "def _write_manifest(export_root: Path, run_root: Path):\n",
    "    repro = _load_repro_from_run(run_root)\n",
    "    git_now = _git_snapshot_now(repo_root)\n",
    "\n",
    "    run_commit = repro.get(\"commit_hash\")\n",
    "    run_dirty = repro.get(\"git_dirty\")\n",
    "\n",
    "    commit_hash = run_commit or git_now.get(\"commit_hash\")\n",
    "    commit_hash_source = \"run_metadata_or_plan\" if run_commit else \"git_at_export\"\n",
    "\n",
    "    git_dirty = run_dirty\n",
    "    if run_dirty is not None:\n",
    "        git_dirty_source = \"plan.json\"\n",
    "    elif git_now.get(\"git_dirty\") is not None:\n",
    "        git_dirty = git_now.get(\"git_dirty\")\n",
    "        git_dirty_source = \"git_status_at_export\"\n",
    "    else:\n",
    "        git_dirty_source = \"unavailable\"\n",
    "\n",
    "    plan_json_present = (run_root / \"plan.json\").exists()\n",
    "    copied = []\n",
    "    for p in export_root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.name == \"EXPORT_MANIFEST.json\":\n",
    "            continue\n",
    "        copied.append(p.relative_to(export_root).as_posix())\n",
    "    payload = {\n",
    "        \"timestamp_utc\": _utc_now_iso(),\n",
    "        \"source_run\": str(run_root),\n",
    "        \"repo_root\": str(repo_root),\n",
    "        \"plan_json_present\": plan_json_present,\n",
    "        \"commit_hash\": commit_hash,\n",
    "        \"commit_hash_source\": commit_hash_source,\n",
    "        \"git_dirty\": git_dirty,\n",
    "        \"git_dirty_source\": git_dirty_source,\n",
    "        \"export_time_git\": git_now,\n",
    "        \"methods\": repro.get(\"methods\"),\n",
    "        \"copied_files\": sorted(copied),\n",
    "    }\n",
    "    (export_root / \"EXPORT_MANIFEST.json\").write_text(\n",
    "        json.dumps(payload, indent=2, ensure_ascii=False),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "\n",
    "def _copy_files(src_paths: list[Path], dst_dir: Path) -> list[Path]:\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "    copied = []\n",
    "    for src in src_paths:\n",
    "        try:\n",
    "            if src.exists() and src.is_file():\n",
    "                dst = dst_dir / src.name\n",
    "                shutil.copy2(src, dst)\n",
    "                copied.append(dst)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return copied\n",
    "\n",
    "\n",
    "def _discover_instances(run_root: Path) -> list[str]:\n",
    "    fig_dir = run_root / \"stage3_evaluation\" / \"figures\"\n",
    "    if not fig_dir.exists():\n",
    "        return []\n",
    "    is_ids = set()\n",
    "    for p in fig_dir.glob(\"parallel_coords__*.pdf\"):\n",
    "        stem = p.stem\n",
    "        if stem.startswith(\"parallel_coords__\"):\n",
    "            is_ids.add(stem[len(\"parallel_coords__\"):])\n",
    "    for p in fig_dir.glob(\"pareto_scatter__*.pdf\"):\n",
    "        stem = p.stem\n",
    "        if stem.startswith(\"pareto_scatter__\"):\n",
    "            # pareto_scatter__{is_id}__f_x__f_y\n",
    "            rest = stem[len(\"pareto_scatter__\"):]\n",
    "            parts = rest.split(\"__\")\n",
    "            if len(parts) >= 3:\n",
    "                is_ids.add(\"__\".join(parts[:-2]))\n",
    "    return sorted(is_ids)\n",
    "\n",
    "\n",
    "def refresh_instances():\n",
    "    run_root = _get_selected_run_root()\n",
    "    if run_root is None:\n",
    "        w_is_select.options = [(\"(kein Run geladen)\", \"\")]\n",
    "        w_is_select.value = \"\"\n",
    "        return\n",
    "    is_ids = _discover_instances(run_root)\n",
    "    if not is_ids:\n",
    "        w_is_select.options = [(\"(keine Instanzen gefunden)\", \"\")]\n",
    "        w_is_select.value = \"\"\n",
    "        return\n",
    "    w_is_select.options = [(x, x) for x in is_ids]\n",
    "    if not w_is_select.value:\n",
    "        w_is_select.value = is_ids[0]\n",
    "\n",
    "\n",
    "def _on_export_tables(_):\n",
    "    with out_export:\n",
    "        clear_output()\n",
    "        run_root = _get_selected_run_root()\n",
    "        if run_root is None:\n",
    "            display(_html_box(\"Kein Run ausgewählt (Report zuerst laden).\", kind=\"warn\"))\n",
    "            return\n",
    "        export_root = _export_root_for_run(run_root)\n",
    "        src_dir = run_root / \"stage3_evaluation\" / \"tables\"\n",
    "        if not src_dir.exists():\n",
    "            display(_html_box(f\"Fehlt: {src_dir}\", kind=\"error\"))\n",
    "            return\n",
    "        src_files = sorted(src_dir.glob(\"*.tex\"))\n",
    "        copied = _copy_files(src_files, export_root / \"tables\")\n",
    "        display(_html_box(f\"Exportiert {len(copied)} LaTeX-Tabellen nach: {export_root}\", kind=\"ok\"))\n",
    "        _write_manifest(export_root, run_root)\n",
    "\n",
    "\n",
    "def _on_export_figs(_):\n",
    "    with out_export:\n",
    "        clear_output()\n",
    "        run_root = _get_selected_run_root()\n",
    "        if run_root is None:\n",
    "            display(_html_box(\"Kein Run ausgewählt (Report zuerst laden).\", kind=\"warn\"))\n",
    "            return\n",
    "        export_root = _export_root_for_run(run_root)\n",
    "        fig_dir = run_root / \"stage3_evaluation\" / \"figures\"\n",
    "        if not fig_dir.exists():\n",
    "            display(_html_box(f\"Fehlt: {fig_dir}\", kind=\"error\"))\n",
    "            return\n",
    "\n",
    "        key_names = [\n",
    "            \"boxplots.pdf\",\n",
    "            \"winrate_heatmap.pdf\",\n",
    "            \"coverage_boxplots.pdf\",  # fallback wird unten ergänzt\n",
    "            \"boxplots_coverage.pdf\",\n",
    "        ]\n",
    "        key_files = []\n",
    "        for n in key_names:\n",
    "            p = fig_dir / n\n",
    "            if p.exists():\n",
    "                key_files.append(p)\n",
    "\n",
    "        copied = _copy_files(key_files, export_root / \"figures\")\n",
    "\n",
    "        # ausgewählte Instanz: max. 3 zusätzliche PDFs (parallel_coords + 2x pareto_scatter)\n",
    "        is_id = str(w_is_select.value or \"\").strip()\n",
    "        extra = []\n",
    "        if is_id:\n",
    "            pc = fig_dir / f\"parallel_coords__{is_id}.pdf\"\n",
    "            if pc.exists():\n",
    "                extra.append(pc)\n",
    "\n",
    "            scat = sorted(fig_dir.glob(f\"pareto_scatter__{is_id}__*.pdf\"))\n",
    "            limit = 2 if extra else 3\n",
    "            extra.extend(scat[:limit])\n",
    "        copied += _copy_files(extra, export_root / \"figures\")\n",
    "\n",
    "        display(_html_box(f\"Exportiert {len(copied)} Abbildungen nach: {export_root}\", kind=\"ok\"))\n",
    "        _write_manifest(export_root, run_root)\n",
    "\n",
    "\n",
    "def _on_export_csv(_):\n",
    "    with out_export:\n",
    "        clear_output()\n",
    "        run_root = _get_selected_run_root()\n",
    "        if run_root is None:\n",
    "            display(_html_box(\"Kein Run ausgewählt (Report zuerst laden).\", kind=\"warn\"))\n",
    "            return\n",
    "        export_root = _export_root_for_run(run_root)\n",
    "        stage3_dir = run_root / \"stage3_evaluation\"\n",
    "        if not stage3_dir.exists():\n",
    "            display(_html_box(f\"Fehlt: {stage3_dir}\", kind=\"error\"))\n",
    "            return\n",
    "\n",
    "        names = [\n",
    "            \"aggregated_metrics.csv\",\n",
    "            \"per_instance_metrics.csv\",\n",
    "            \"coverage_matrix.csv\",\n",
    "            \"coverage_matrix_aggregated.csv\",\n",
    "            \"winrate_heatmap.csv\",\n",
    "            \"winrate_per_is.csv\",\n",
    "            \"milp_subruns.csv\",\n",
    "        ]\n",
    "        src = [p for p in (stage3_dir / n for n in names) if p.exists()]\n",
    "        copied = _copy_files(src, export_root / \"csv\")\n",
    "        display(_html_box(f\"Exportiert {len(copied)} CSVs nach: {export_root}\", kind=\"ok\"))\n",
    "        _write_manifest(export_root, run_root)\n",
    "\n",
    "\n",
    "btn_export_tables.on_click(_on_export_tables)\n",
    "btn_export_figs.on_click(_on_export_figs)\n",
    "btn_export_csv.on_click(_on_export_csv)\n",
    "btn_refresh_is.on_click(lambda _: refresh_instances())\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([btn_refresh_is, w_is_select]),\n",
    "    widgets.HBox([btn_export_tables, btn_export_figs, btn_export_csv]),\n",
    "    out_export,\n",
    "]))\n",
    "\n",
    "refresh_instances()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "checklist-md",
   "metadata": {},
   "source": [
    "## 9) Kleiner Hinweis für die Arbeit\n",
    "\n",
    "Für den Text/LaTeX nutze ich in der Regel nur die Dateien aus `thesis_assets/<run_name>/`. So sind die Pfade stabil, und im Export-Manifest steht immer dabei, aus welchem Lauf (Commit/Seeds/Budget) eine Tabelle oder Abbildung stammt.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
